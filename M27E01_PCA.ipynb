{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aluna: Cristina Freitas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA - Tarefa 01: *HAR* com PCA\n",
    "\n",
    "Vamos trabalhar com a base da demonstração feita em aula, mas vamos explorar um pouco melhor como é o desempenho da árvore variando o número de componentes principais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename_features = \"UCI HAR Dataset/features.txt\"\n",
    "filename_labels = \"UCI HAR Dataset/activity_labels.txt\"\n",
    "\n",
    "filename_subtrain = \"UCI HAR Dataset/train/subject_train.txt\"\n",
    "filename_xtrain = \"UCI HAR Dataset/train/X_train.txt\"\n",
    "filename_ytrain = \"UCI HAR Dataset/train/y_train.txt\"\n",
    "\n",
    "filename_subtest = \"UCI HAR Dataset/test/subject_test.txt\"\n",
    "filename_xtest = \"UCI HAR Dataset/test/X_test.txt\"\n",
    "filename_ytest = \"UCI HAR Dataset/test/y_test.txt\"\n",
    "\n",
    "# Removido squeeze=True\n",
    "features_df = pd.read_csv(filename_features, header=None, names=['nome_var'], sep=\"#\")\n",
    "features = features_df['nome_var']  # Convertido manualmente para Series\n",
    "\n",
    "labels = pd.read_csv(filename_labels, delim_whitespace=True, header=None, names=['cod_label', 'label'])\n",
    "\n",
    "subject_train_df = pd.read_csv(filename_subtrain, header=None, names=['subject_id'])\n",
    "subject_train = subject_train_df['subject_id']  # Convertido para Series\n",
    "\n",
    "X_train = pd.read_csv(filename_xtrain, delim_whitespace=True, header=None, names=features.tolist())\n",
    "y_train = pd.read_csv(filename_ytrain, header=None, names=['cod_label'])\n",
    "\n",
    "subject_test_df = pd.read_csv(filename_subtest, header=None, names=['subject_id'])\n",
    "subject_test = subject_test_df['subject_id']  # Convertido para Series\n",
    "\n",
    "X_test = pd.read_csv(filename_xtest, delim_whitespace=True, header=None, names=features.tolist())\n",
    "y_test = pd.read_csv(filename_ytest, header=None, names=['cod_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore de decisão\n",
    "\n",
    "Rode uma árvore de decisão com todas as variáveis, utilizando o ```ccp_alpha=0.001```. Avalie a acurácia nas bases de treinamento e teste. Avalie o tempo de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.53 s\n",
      "Wall time: 4.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    " clf = DecisionTreeClassifier(random_state=2360873, ccp_alpha=0.001).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no Treino: 0.9775117881755532\n",
      "Acurácia na Validação: 0.9287268770402611\n",
      "\n",
      "Matriz de Confusão (Validação):\n",
      "[[307  13   9   0   0   0]\n",
      " [ 17 230  17   0   0   0]\n",
      " [  6   5 243   0   0   0]\n",
      " [  0   0   0 294  35   0]\n",
      " [  0   0   0  29 316   0]\n",
      " [  0   0   0   0   0 317]]\n",
      "\n",
      "Relatório de Classificação (Validação):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.93      0.93       329\n",
      "           2       0.93      0.87      0.90       264\n",
      "           3       0.90      0.96      0.93       254\n",
      "           4       0.91      0.89      0.90       329\n",
      "           5       0.90      0.92      0.91       345\n",
      "           6       1.00      1.00      1.00       317\n",
      "\n",
      "    accuracy                           0.93      1838\n",
      "   macro avg       0.93      0.93      0.93      1838\n",
      "weighted avg       0.93      0.93      0.93      1838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Previsões\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_valid_pred = clf.predict(X_valid)\n",
    "\n",
    "# Acurácia\n",
    "print(\"Acurácia no Treino:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Acurácia na Validação:\", accuracy_score(y_valid, y_valid_pred))\n",
    "\n",
    "# Matriz de confusão\n",
    "print(\"\\nMatriz de Confusão (Validação):\")\n",
    "print(confusion_matrix(y_valid, y_valid_pred))\n",
    "\n",
    "# Relatório de classificação\n",
    "print(\"\\nRelatório de Classificação (Validação):\")\n",
    "print(classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore com PCA\n",
    "\n",
    "Faça uma análise de componemtes principais das variáveis originais. Utilize apenas uma componente. Faça uma árvore de decisão com esta componente como variável explicativa.\n",
    "\n",
    "- Avalie a acurácia nas bases de treinamento e teste\n",
    "- Avalie o tempo de processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 328 ms\n",
      "Wall time: 204 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5514, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prcomp = PCA(n_components=1).fit(X_train)\n",
    "\n",
    "pc_treino = prcomp.transform(X_train)\n",
    "pc_valida = prcomp.transform(X_valid)\n",
    "pc_teste  = prcomp.transform(X_test)\n",
    "\n",
    "pc_treino.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o número de componentes\n",
    "\n",
    "Com base no código acima, teste a árvore de classificação com pelo menos as seguintes possibilidades de quantidades de componentes: ```[1, 2, 5, 10, 50]```. Avalie para cada uma delas:\n",
    "\n",
    "- Acurácia nas bases de treino e teste\n",
    "- Tempo de processamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando com 1 componentes principais:\n",
      "Acurácia no Treino (com 1 componentes): 0.4949\n",
      "Acurácia na Validação (com 1 componentes): 0.4940\n",
      "\n",
      "Matriz de Confusão (com 1 componentes):\n",
      "[[149  77 103   0   0   0]\n",
      " [ 97  98  69   0   0   0]\n",
      " [ 40  10 204   0   0   0]\n",
      " [  0   0   0  52 262  15]\n",
      " [  0   0   0  27 318   0]\n",
      " [  0   0   0  43 187  87]]\n",
      "\n",
      "Relatório de Classificação (com 1 componentes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.45      0.48       329\n",
      "           2       0.53      0.37      0.44       264\n",
      "           3       0.54      0.80      0.65       254\n",
      "           4       0.43      0.16      0.23       329\n",
      "           5       0.41      0.92      0.57       345\n",
      "           6       0.85      0.27      0.42       317\n",
      "\n",
      "    accuracy                           0.49      1838\n",
      "   macro avg       0.55      0.50      0.46      1838\n",
      "weighted avg       0.55      0.49      0.46      1838\n",
      "\n",
      "\n",
      "Treinando com 2 componentes principais:\n",
      "Acurácia no Treino (com 2 componentes): 0.6262\n",
      "Acurácia na Validação (com 2 componentes): 0.5914\n",
      "\n",
      "Matriz de Confusão (com 2 componentes):\n",
      "[[219  47  63   0   0   0]\n",
      " [ 16 230  18   0   0   0]\n",
      " [ 49  50 155   0   0   0]\n",
      " [  0   0   0 103 175  51]\n",
      " [  0   0   0  76 244  25]\n",
      " [  0   0   0  62 119 136]]\n",
      "\n",
      "Relatório de Classificação (com 2 componentes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.67      0.71       329\n",
      "           2       0.70      0.87      0.78       264\n",
      "           3       0.66      0.61      0.63       254\n",
      "           4       0.43      0.31      0.36       329\n",
      "           5       0.45      0.71      0.55       345\n",
      "           6       0.64      0.43      0.51       317\n",
      "\n",
      "    accuracy                           0.59      1838\n",
      "   macro avg       0.61      0.60      0.59      1838\n",
      "weighted avg       0.60      0.59      0.58      1838\n",
      "\n",
      "\n",
      "Treinando com 5 componentes principais:\n",
      "Acurácia no Treino (com 5 componentes): 0.8546\n",
      "Acurácia na Validação (com 5 componentes): 0.8112\n",
      "\n",
      "Matriz de Confusão (com 5 componentes):\n",
      "[[276  26  27   0   0   0]\n",
      " [ 15 219  30   0   0   0]\n",
      " [ 17  32 205   0   0   0]\n",
      " [  0   0   0 195 127   7]\n",
      " [  0   0   0  64 281   0]\n",
      " [  0   0   0   2   0 315]]\n",
      "\n",
      "Relatório de Classificação (com 5 componentes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.84      0.87       329\n",
      "           2       0.79      0.83      0.81       264\n",
      "           3       0.78      0.81      0.79       254\n",
      "           4       0.75      0.59      0.66       329\n",
      "           5       0.69      0.81      0.75       345\n",
      "           6       0.98      0.99      0.99       317\n",
      "\n",
      "    accuracy                           0.81      1838\n",
      "   macro avg       0.81      0.81      0.81      1838\n",
      "weighted avg       0.81      0.81      0.81      1838\n",
      "\n",
      "\n",
      "Treinando com 10 componentes principais:\n",
      "Acurácia no Treino (com 10 componentes): 0.8993\n",
      "Acurácia na Validação (com 10 componentes): 0.8564\n",
      "\n",
      "Matriz de Confusão (com 10 componentes):\n",
      "[[288  21  20   0   0   0]\n",
      " [ 11 226  27   0   0   0]\n",
      " [ 15  21 218   0   0   0]\n",
      " [  0   0   0 222  99   8]\n",
      " [  0   0   0  41 304   0]\n",
      " [  0   0   0   1   0 316]]\n",
      "\n",
      "Relatório de Classificação (com 10 componentes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.88      0.90       329\n",
      "           2       0.84      0.86      0.85       264\n",
      "           3       0.82      0.86      0.84       254\n",
      "           4       0.84      0.67      0.75       329\n",
      "           5       0.75      0.88      0.81       345\n",
      "           6       0.98      1.00      0.99       317\n",
      "\n",
      "    accuracy                           0.86      1838\n",
      "   macro avg       0.86      0.86      0.86      1838\n",
      "weighted avg       0.86      0.86      0.86      1838\n",
      "\n",
      "\n",
      "Treinando com 50 componentes principais:\n",
      "Acurácia no Treino (com 50 componentes): 0.9316\n",
      "Acurácia na Validação (com 50 componentes): 0.8531\n",
      "\n",
      "Matriz de Confusão (com 50 componentes):\n",
      "[[304  10  15   0   0   0]\n",
      " [ 21 220  23   0   0   0]\n",
      " [ 22  20 212   0   0   0]\n",
      " [  0   0   0 245  77   7]\n",
      " [  0   0   0  72 273   0]\n",
      " [  0   0   0   3   0 314]]\n",
      "\n",
      "Relatório de Classificação (com 50 componentes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.92      0.90       329\n",
      "           2       0.88      0.83      0.86       264\n",
      "           3       0.85      0.83      0.84       254\n",
      "           4       0.77      0.74      0.76       329\n",
      "           5       0.78      0.79      0.79       345\n",
      "           6       0.98      0.99      0.98       317\n",
      "\n",
      "    accuracy                           0.85      1838\n",
      "   macro avg       0.85      0.85      0.85      1838\n",
      "weighted avg       0.85      0.85      0.85      1838\n",
      "\n",
      "CPU times: total: 3.56 s\n",
      "Wall time: 2.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Quantidades de componentes a serem testadas\n",
    "componentes_list = [1, 2, 5, 10, 50]\n",
    "\n",
    "# Dicionário para armazenar os resultados\n",
    "resultados = {}\n",
    "\n",
    "# Loop para testar com diferentes quantidades de componentes\n",
    "for n_components in componentes_list:\n",
    "    print(f\"\\nTreinando com {n_components} componentes principais:\")\n",
    "    \n",
    "    # 1. Realiza o PCA com n_components\n",
    "    pca = PCA(n_components=n_components)\n",
    "    \n",
    "    pc_treino = pca.fit_transform(X_train)\n",
    "    pc_valida = pca.transform(X_valid)\n",
    "    pc_teste  = pca.transform(X_test)\n",
    "    \n",
    "    # 2. Treina a árvore de decisão\n",
    "    clf = DecisionTreeClassifier(random_state=2360873, ccp_alpha=0.001)\n",
    "    clf.fit(pc_treino, y_train)\n",
    "    \n",
    "    # 3. Faz as previsões\n",
    "    y_train_pred = clf.predict(pc_treino)\n",
    "    y_valid_pred = clf.predict(pc_valida)\n",
    "    \n",
    "    # 4. Avalia o desempenho\n",
    "    acuracia_treino = accuracy_score(y_train, y_train_pred)\n",
    "    acuracia_validacao = accuracy_score(y_valid, y_valid_pred)\n",
    "    \n",
    "    # 5. Matriz de confusão e relatório de classificação\n",
    "    matriz_confusao = confusion_matrix(y_valid, y_valid_pred)\n",
    "    relatorio_classificacao = classification_report(y_valid, y_valid_pred)\n",
    "    \n",
    "    # 6. Armazena os resultados\n",
    "    resultados[n_components] = {\n",
    "        \"acuracia_treino\": acuracia_treino,\n",
    "        \"acuracia_validacao\": acuracia_validacao,\n",
    "        \"matriz_confusao\": matriz_confusao,\n",
    "        \"relatorio_classificacao\": relatorio_classificacao\n",
    "    }\n",
    "\n",
    "    # Exibe as métricas para o conjunto de validação\n",
    "    print(f\"Acurácia no Treino (com {n_components} componentes): {acuracia_treino:.4f}\")\n",
    "    print(f\"Acurácia na Validação (com {n_components} componentes): {acuracia_validacao:.4f}\")\n",
    "    print(f\"\\nMatriz de Confusão (com {n_components} componentes):\\n{matriz_confusao}\")\n",
    "    print(f\"\\nRelatório de Classificação (com {n_components} componentes):\\n{relatorio_classificacao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclua\n",
    "\n",
    "- O que aconteceu com a acurácia?\n",
    "- O que aconteceu com o tempo de processamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que aconteceu com a acurária? \n",
    "\n",
    "Quando temos poucas variáveis (exemplo: n=1) podemos perder informação e não temos como observar a complexidade do modelo. \n",
    "Como efeito disso podemos ter overfitting ou underfitting pois com poucos dados o modelo tem dificuldade de se adaptar. \n",
    "Contudo, com muita informação (exemplo: n=50) se consegue capturar as complexidades do modelo, porém o excesso tende ao \n",
    "overfitting (ou excesso de adaptação)\n",
    "\n",
    "\n",
    "\n",
    "O que aconteceu com o tempo de processamento?\n",
    "\n",
    "Quanto maior a quantidade de dados maior o tempo de processamento e quanto menor a quantidade de dados menor o tempo de \n",
    "processamento. No entanto, se o número de componentes for pequeno pode-se perder uma representação significativa dos dados.\n",
    "\n",
    "\n",
    "\n",
    "O que seria o melhor dos mundos?\n",
    "\n",
    "Poderíamos usar a validação cruzada para observar o comportamento da acurária no contexto das quantidades de variáveis.\n",
    "Outra coisa seria ajustar o parâmetro ccp_alpha para regular a complexidade e evitar o overfitting e utilizar um gráfico \n",
    "onde mostre acurária x número de componentes para saber o tempo ótimo de equilíbrio entre desempenho e tempo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Conteúdo",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
